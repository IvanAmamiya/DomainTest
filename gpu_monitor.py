#!/usr/bin/env python3
"""
GPUå’Œæ˜¾å­˜ç›‘æ§å·¥å…·
"""

import torch
import time
import os
import subprocess
import psutil
from datetime import datetime


class GPUMonitor:
    """GPUç›‘æ§å™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.gpu_available = torch.cuda.is_available()
        
    def get_gpu_memory_info(self):
        """è·å–GPUæ˜¾å­˜ä¿¡æ¯"""
        if not self.gpu_available:
            return {"error": "CUDAä¸å¯ç”¨"}
        
        # PyTorchæ˜¾å­˜ä¿¡æ¯
        allocated = torch.cuda.memory_allocated(self.device)
        reserved = torch.cuda.memory_reserved(self.device)
        total_memory = torch.cuda.get_device_properties(self.device).total_memory
        
        # è½¬æ¢ä¸ºMB
        allocated_mb = allocated / 1024**2
        reserved_mb = reserved / 1024**2
        total_mb = total_memory / 1024**2
        free_mb = total_mb - reserved_mb
        
        return {
            "device": torch.cuda.get_device_name(self.device),
            "allocated_mb": allocated_mb,
            "reserved_mb": reserved_mb,
            "total_mb": total_mb,
            "free_mb": free_mb,
            "utilization_percent": (reserved_mb / total_mb) * 100
        }
    
    def get_nvidia_smi_info(self):
        """ä½¿ç”¨nvidia-smiè·å–GPUä¿¡æ¯"""
        try:
            result = subprocess.run([
                'nvidia-smi', 
                '--query-gpu=name,memory.total,memory.used,memory.free,utilization.gpu,temperature.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, check=True)
            
            lines = result.stdout.strip().split('\n')
            gpu_info = []
            
            for i, line in enumerate(lines):
                parts = [part.strip() for part in line.split(',')]
                if len(parts) >= 6:
                    gpu_info.append({
                        "gpu_id": i,
                        "name": parts[0],
                        "total_memory_mb": float(parts[1]),
                        "used_memory_mb": float(parts[2]),
                        "free_memory_mb": float(parts[3]),
                        "gpu_utilization_percent": float(parts[4]),
                        "temperature_c": float(parts[5])
                    })
            
            return gpu_info
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            return {"error": f"nvidia-smiå‘½ä»¤å¤±è´¥: {e}"}
    
    def print_memory_summary(self):
        """æ‰“å°æ˜¾å­˜ä½¿ç”¨æ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"GPUæ˜¾å­˜ç›‘æ§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        if not self.gpu_available:
            print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•ç›‘æ§GPU")
            return
        
        # PyTorchæ˜¾å­˜ä¿¡æ¯
        pytorch_info = self.get_gpu_memory_info()
        print(f"ğŸ”¹ è®¾å¤‡: {pytorch_info['device']}")
        print(f"ğŸ”¹ PyTorchæ˜¾å­˜:")
        print(f"   - å·²åˆ†é…: {pytorch_info['allocated_mb']:.1f} MB")
        print(f"   - å·²ä¿ç•™: {pytorch_info['reserved_mb']:.1f} MB") 
        print(f"   - æ€»å®¹é‡: {pytorch_info['total_mb']:.1f} MB")
        print(f"   - ä½¿ç”¨ç‡: {pytorch_info['utilization_percent']:.1f}%")
        
        # nvidia-smiä¿¡æ¯
        nvidia_info = self.get_nvidia_smi_info()
        if isinstance(nvidia_info, list) and len(nvidia_info) > 0:
            gpu = nvidia_info[0]  # å‡è®¾ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
            print(f"\nğŸ”¹ nvidia-smiæ˜¾å­˜:")
            print(f"   - å·²ä½¿ç”¨: {gpu['used_memory_mb']:.1f} MB")
            print(f"   - å¯ç”¨: {gpu['free_memory_mb']:.1f} MB")
            print(f"   - æ€»å®¹é‡: {gpu['total_memory_mb']:.1f} MB")
            print(f"   - GPUåˆ©ç”¨ç‡: {gpu['gpu_utilization_percent']:.1f}%")
            print(f"   - æ¸©åº¦: {gpu['temperature_c']:.1f}Â°C")
        
        print(f"{'='*60}")
    
    def monitor_during_training(self, interval=10):
        """è®­ç»ƒæœŸé—´æŒç»­ç›‘æ§"""
        print(f"å¼€å§‹GPUç›‘æ§ï¼Œæ¯{interval}ç§’æ›´æ–°ä¸€æ¬¡...")
        print("æŒ‰Ctrl+Cåœæ­¢ç›‘æ§")
        
        try:
            while True:
                self.print_memory_summary()
                time.sleep(interval)
        except KeyboardInterrupt:
            print("\nç›‘æ§å·²åœæ­¢")
    
    def clear_cache(self):
        """æ¸…ç†PyTorchç¼“å­˜"""
        if self.gpu_available:
            torch.cuda.empty_cache()
            print("âœ… PyTorch GPUç¼“å­˜å·²æ¸…ç†")
        else:
            print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— éœ€æ¸…ç†ç¼“å­˜")


def monitor_memory_usage(func):
    """è£…é¥°å™¨ï¼šç›‘æ§å‡½æ•°æ‰§è¡ŒæœŸé—´çš„æ˜¾å­˜ä½¿ç”¨"""
    def wrapper(*args, **kwargs):
        monitor = GPUMonitor()
        
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œå‡½æ•°: {func.__name__}")
        monitor.print_memory_summary()
        
        result = func(*args, **kwargs)
        
        print(f"\nâœ… å‡½æ•°æ‰§è¡Œå®Œæˆ: {func.__name__}")
        monitor.print_memory_summary()
        
        return result
    return wrapper


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="GPUæ˜¾å­˜ç›‘æ§å·¥å…·")
    parser.add_argument("--monitor", action="store_true", help="æŒç»­ç›‘æ§æ¨¡å¼")
    parser.add_argument("--interval", type=int, default=5, help="ç›‘æ§é—´éš”(ç§’)")
    parser.add_argument("--clear", action="store_true", help="æ¸…ç†PyTorchç¼“å­˜")
    
    args = parser.parse_args()
    
    monitor = GPUMonitor()
    
    if args.clear:
        monitor.clear_cache()
    
    if args.monitor:
        monitor.monitor_during_training(args.interval)
    else:
        monitor.print_memory_summary()
